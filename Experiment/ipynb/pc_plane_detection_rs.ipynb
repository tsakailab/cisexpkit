{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sNuBXVKBTSM"
      },
      "source": [
        "# ポイントクラウドを用いた平面の検出\n",
        "\n",
        "\n",
        "Q16: ベクトル $\\bf a$ のノルム（長さ）を $\\|\\bf a\\|$と記す．また，ベクトル $\\bf a$ と $\\bf b$の内積を ${\\bf a}\\cdot{\\bf b}$，外積を ${\\bf a}\\times{\\bf b}$ と記す．__これらの記法を用いて__，「位置ベクトル ${\\bf p}_0$，${\\bf p}_1$，${\\bf p}_2$ の3点を通る平面」と「位置ベクトル $\\bf p$ の点」の間の距離 $d$ を求める公式を作れ．また，この公式を図を用いて解説せよ．"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yW-_iTAcHZrP"
      },
      "source": [
        "## RealSenseで平面を撮像してください．\n",
        "> 机や壁と多面体など，なるべく2つ以上の面が広く写るように撮影しましょう．\n",
        "\n",
        "> このファイルの内容は，★印まで pointcloud_rs.ipynb と同じです．★印まで同様に作業を進めてください． "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gwSngoUHZrQ"
      },
      "source": [
        "import pyrealsense2 as rs\n",
        "import numpy as np\n",
        "import cv2\n",
        "from IPython.display import Image, display\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Configure color and depth to run at VGA resolution at 30 frames per second\n",
        "config = rs.config()\n",
        "config.enable_stream(rs.stream.depth)\n",
        "config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)\n",
        "config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xZKJD5IHZrR"
      },
      "source": [
        "## カラー画像と深度画像を取得して表示・保存します．\n",
        "スペースキーを押す毎に画像が連番で保存されます．'q'を押すと終了します．最後に保存したデータが点群の作成に使われます．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLRT7cr-HZrR"
      },
      "source": [
        "# Start streaming\n",
        "pipeline = rs.pipeline()\n",
        "profile = pipeline.start(config)\n",
        "\n",
        "# Get camera parameters\n",
        "intr = profile.get_stream(rs.stream.depth).as_video_stream_profile().get_intrinsics()\n",
        "scale = config.resolve(rs.pipeline_wrapper(pipeline)).get_device().first_depth_sensor().get_depth_scale()\n",
        "\n",
        "print(\"focal length(x) in pixels = \", intr.fx)\n",
        "print(\"focal length(y) in pixels = \", intr.fy)\n",
        "print(\"image height = \", intr.height)\n",
        "print(\"image width = \", intr.width)\n",
        "print(\"ppx = \", intr.ppx)\n",
        "print(\"ppy = \", intr.ppy)\n",
        "\n",
        "# Create a camera alignment object (depth aligned to color)\n",
        "align = rs.align(rs.stream.color)\n",
        "max_depth = 2.0 / scale # Zeros out for any depth greater than 2.0 meters\n",
        "\n",
        "# Display and save images\n",
        "print(\"Press [SPACE] to save images (png) and depth data (npy).\")\n",
        "print(\"Press 'q' to stop.\")\n",
        "nsaved = 0\n",
        "try:\n",
        "    while True:\n",
        "        # Wait for a coherent pair of frames: depth and color\n",
        "        frames = pipeline.wait_for_frames()\n",
        "        aligned_frames = align.process(frames)\n",
        "        color_frame = aligned_frames.get_color_frame()\n",
        "        depth_frame = aligned_frames.get_depth_frame()\n",
        "        if not depth_frame or not color_frame:\n",
        "            continue\n",
        "\n",
        "        # Convert images to numpy arrays\n",
        "        bgr = np.asanyarray(color_frame.get_data())\n",
        "        depth = np.asanyarray(depth_frame.get_data())\n",
        "        depth[depth > max_depth] = 0 # Zeros out\n",
        "\n",
        "        # Apply colormap on depth image (image must be converted to 8-bit per pixel first)\n",
        "        depth_colormap = cv2.applyColorMap(cv2.normalize(depth, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U), \n",
        "                                           cv2.COLORMAP_JET)\n",
        "  \n",
        "        images = np.hstack((bgr, depth_colormap))\n",
        "        # Show images\n",
        "        cv2.namedWindow('RealSense', cv2.WINDOW_AUTOSIZE)\n",
        "        cv2.imshow('RealSense', images)\n",
        "        \n",
        "        key = cv2.waitKey(33)\n",
        "        if key == ord(' '):\n",
        "            Z = depth * scale * 1e+3 # unit in mm\n",
        "            color = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)\n",
        "            \n",
        "            # Save images\n",
        "            cv2.imwrite('color{:02d}pc.png'.format(nsaved), bgr)\n",
        "            cv2.imwrite('depth{:02d}pc.png'.format(nsaved), depth_colormap)\n",
        "            np.save('Z{:02d}pc.npy'.format(nsaved), Z)\n",
        "            \n",
        "            print(\"color image and depth data are saved ({:02d})\".format(nsaved))\n",
        "            nsaved += 1\n",
        "\n",
        "        elif key == ord('q'):\n",
        "            if nsaved == 0:\n",
        "                Z = depth * scale * 1e+3 # unit in mm\n",
        "                color = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)\n",
        "            cv2.destroyAllWindows()\n",
        "            break\n",
        "        \n",
        "finally:\n",
        "    # Stop streaming\n",
        "    pipeline.stop()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wv-ooT7HZrS"
      },
      "source": [
        "## 逆透視変換でポイントクラウドを作りましょう．\n",
        "カラー画像および点群を作成する深度データを可視化します．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZiWvW_rHZrT"
      },
      "source": [
        "from PIL import Image\n",
        "height, width, _ = color.shape\n",
        "plt.figure(figsize=(15,4))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(color)\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(Z, cmap=\"gray\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xUoVPekHZrT"
      },
      "source": [
        "### 各画素にuとvの座標を設定します．座標系は[予習事項](https://github.com/tsakailab/cisexpkit/blob/master/Experiment/Document/preparation.pdf)の図1です．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAgyBPiHHZrT"
      },
      "source": [
        "# 主点を設定します．\n",
        "cx, cy = intr.ppx, intr.ppy # width*0.5, height*0.5\n",
        "j_to_u = lambda j: -(j - cx)\n",
        "i_to_v = lambda i: -(i - cy)\n",
        "# 画像平面の座標を設定します．\n",
        "u, v = np.meshgrid(j_to_u(np.arange(width)), i_to_v(np.arange(height)))\n",
        "print(u, u.shape)\n",
        "print(v, v.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ej9jt5nZHZrU"
      },
      "source": [
        "### Z, u, vが与えられたとき，X[mm]とY[mm]を計算する関数を作りましょう．[ヒント：予習事項の問2](https://github.com/tsakailab/cisexpkit/blob/master/Experiment/Document/preparation.pdf)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiHDMZHRHZrU"
      },
      "source": [
        "focal_length = [intr.fx, intr.fy] # in pixels\n",
        "def Zuv_to_XY(Z, u, v, f=focal_length):\n",
        "    ### X = ________   # Z, u, v, f[0], f[1] から必要なものを使って計算する\n",
        "    ### Y = ________   # Z, u, v, f[0], f[1] から必要なものを使って計算する\n",
        "    return X, Y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TD9JHHyTHZrV"
      },
      "source": [
        "# Z, u, v から X, Y を計算します．\n",
        "X, Y = Zuv_to_XY(Z, u, v)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6uZfxppHZrV"
      },
      "source": [
        "## ★ポイントクラウドを可視化して観察しましょう．\n",
        "> マウスで視点や拡大・縮小をコントロールできます．描画領域右上にある機能も活用しましょう．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKkQE6TGHZrV"
      },
      "source": [
        "nd = np.count_nonzero(Z)\n",
        "n = 30000\n",
        "p = np.random.choice(nd, min(n,nd), replace=False)\n",
        "print(\"%d out of %d points are displayed.\" % (n, nd))\n",
        "\n",
        "import plotly.graph_objs as go\n",
        "rgb = color[Z>0][p] # * 1.5 # brighter\n",
        "\n",
        "trace = go.Scatter3d(x=X[Z>0][p], y=Y[Z>0][p], z=Z[Z>0][p], mode='markers',\n",
        "                     marker=dict(size=2, \n",
        "                                color=['rgb({},{},{})'.format(r,g,b) for r,g,b in zip(rgb[:,0], rgb[:,1], rgb[:,2])],\n",
        "                                opacity=0.8))\n",
        "\n",
        "layout = go.Layout(margin=dict(l=0,r=0,b=0,t=0))\n",
        "fig = go.Figure(data=[trace], layout=layout)\n",
        "camera = dict(up=dict(x=0, y=0, z=1), center=dict(x=0, y=-0.4, z=0), eye=dict(x=0, y=0.8, z=-2))\n",
        "fig.update_layout(scene_camera=camera)\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoVz6oH0lUcd"
      },
      "source": [
        "## 最も多い点で表された平面の法線と通る点を推定する関数`DetectPlane`を定義します．\n",
        "[[Tarsha-Kurdi+08]](https://halshs.archives-ouvertes.fr/halshs-00278397/document)によるRANSACアルゴリズムを参考に実装したものです．\n",
        "\n",
        "入力:\n",
        "> `points`:  n行3列のNumPy配列．nは点の数，各列はX,Y,Z座標を表します．\n",
        "\n",
        "> `n_trials`:  試行回数（規定値30回）\n",
        "\n",
        "> `th`:  面からの距離の閾値（規定値3mm）\n",
        "\n",
        "出力\n",
        "> `plane`:  推定した平面のパラメタ．\n",
        "\n",
        ">> `plane[\"normal\"]`:  法線ベクトル\n",
        "\n",
        ">> `plane[\"p3idx\"]`:  通る3点の番号．面は `points[plane[\"p3idx\"][0]]`，`points[plane[\"p3idx\"][1]]`，`points[plane[\"p3idx\"][2]]`の3点を通ります．\n",
        "\n",
        "Q17: [RANSAC](https://en.wikipedia.org/wiki/Random_sample_consensus)とは何か．原理と特長を述べよ．\n",
        "\n",
        "Q18: 関数`DetectPlane`が平面の法線と通る点を推定する仕組みを解説せよ．\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pz7d28I6kK6"
      },
      "source": [
        "def DetectPlane(points, n_trials=30, th=3):\n",
        "\n",
        "    # initial settings\n",
        "    plane = dict(normal=None, p3idx=None)\n",
        "    n_max, dev_min = 0, float(\"inf\")\n",
        "\n",
        "    for i in range(n_trials):\n",
        "        # randomly pick up three points\n",
        "        p3idx = np.random.choice(points.shape[0], 3, replace=False)\n",
        "\n",
        "        # compute a unit normal vector\n",
        "        normal = np.cross(points[p3idx[1]] - points[p3idx[0]], points[p3idx[2]] - points[p3idx[0]])\n",
        "        normal = normal / np.linalg.norm(normal)\n",
        "\n",
        "        # compute distances from the plane with a point p3idx[0] and the normal vector\n",
        "        distances = np.abs(np.dot(points - points[p3idx[0],:], normal))\n",
        "\n",
        "        # find the neighboring points to the plane\n",
        "        pidx_neighbors = np.where(distances < th)[0]\n",
        "        num_neighbors = len(pidx_neighbors)\n",
        "        deviation = np.std(distances[pidx_neighbors])\n",
        "\n",
        "        # check if the plane is better than the current estimate\n",
        "        if num_neighbors > n_max or (num_neighbors == n_max and deviation < dev_min):\n",
        "            n_max, dev_min = num_neighbors, deviation\n",
        "            plane[\"normal\"], plane[\"p3idx\"] = normal, p3idx\n",
        "\n",
        "    return plane"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTd7F9K08LAU"
      },
      "source": [
        "### ポイントクラウドに適用して，最大の平面を検出します．\n",
        "\n",
        "Q19: 表示されるヒストグラムは何を表しているか．このヒストグラムから何がわかるか．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08UI8ZK-B0AI"
      },
      "source": [
        "points = np.vstack((X[Z>0],Y[Z>0],Z[Z>0])).T\n",
        "plane1 = DetectPlane(points, n_trials=100, th=5)\n",
        "\n",
        "print(\"Estimated unit normal vector =\", plane1[\"normal\"])\n",
        "distances1 = np.abs(np.dot(points - points[plane1[\"p3idx\"][0],:], plane1[\"normal\"]))\n",
        "import matplotlib.pyplot as plt\n",
        "_ = plt.hist(distances1, bins=50)\n",
        "plt.xlabel(\"Distance [mm]\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4B7mZ1a9_Yv"
      },
      "source": [
        "### 検出した平面に近い点を着色して表示します．\n",
        "\n",
        "「検出」の誤りは2種類あります．誤検出（false positive detection）と検出漏れ（false negative detection）です．平面の検出では，どのような原因で誤検出や検出漏れが起きるでしょうか．実験的に具体例を示しながら考察してください．\n",
        "\n",
        "Q20: 入力の `n_trials` や `th` の値が大きい・小さいと，`DetectPlane`による平面の検出結果はどうなるか．表示される図を用いて説明せよ．また，その結果になる原因を考察せよ．\n",
        "> 前のセル（`plane1 = ...`）で入力を変えて実行し，次のセル（`# plot the neighboring ...`）で表示・観察する．\n",
        "\n",
        "> 入力が同じでも`DetectPlane`は実行する毎に異なる結果を出力することがある．反復して観察すること． "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DqSBAL_9xSx"
      },
      "source": [
        "# plot the neighboring points to the plane within 10mm\n",
        "disp_mm = 10.\n",
        "pidx_on_plane1 = np.where(distances1 < disp_mm)[0]\n",
        "p1 = np.intersect1d(p, pidx_on_plane1)\n",
        "print(\"Points within %2.0f mm of the plane are shown in green.\" % (disp_mm))\n",
        "xyz = points[p1,:]\n",
        "\n",
        "trace_p1 = go.Scatter3d(x=xyz[:,0], y=xyz[:,1], z=xyz[:,2], mode='markers',\n",
        "                           marker=dict(size=2, color='rgb(0,255,0)',\n",
        "                           opacity=0.05))\n",
        "\n",
        "layout = go.Layout(margin=dict(l=0,r=0,b=0,t=0))\n",
        "fig = go.Figure(data=[trace, trace_p1], layout=layout)\n",
        "camera = dict(up=dict(x=0, y=0, z=1), center=dict(x=0, y=-0.4, z=0), eye=dict(x=0, y=0.8, z=-2))\n",
        "fig.update_layout(scene_camera=camera)\n",
        "\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ECON2I8Blql"
      },
      "source": [
        "### 検出した平面に近い点を除いたポイントクラウドから，再び平面を検出します．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3T4jkaN-SEO"
      },
      "source": [
        "points1 = np.delete(points, pidx_on_plane1, axis=0)\n",
        "\n",
        "plane2 = DetectPlane(points1, n_trials=100, th=5)\n",
        "\n",
        "print(\"Estimated unit normal vector =\", plane2[\"normal\"])\n",
        "distances2 = np.abs(np.dot(points - points[plane2[\"p3idx\"][0],:], plane2[\"normal\"]))\n",
        "import matplotlib.pyplot as plt\n",
        "_ = plt.hist(distances2, bins=50)\n",
        "plt.xlabel(\"Distance [mm]\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDW6kyEYB9JB"
      },
      "source": [
        "### 検出した平面に近い点を着色して表示します．\n",
        "\n",
        "どのような平面が2つ目の平面として検出されますか．前のセル（`points1 = ...`）と次のセル（`# plot the neighboring ...`）の実行を何度か繰り返して観察してください．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_C5k8pC-jp8"
      },
      "source": [
        "# plot the neighboring points to the plane within 10mm\n",
        "disp_mm = 10.\n",
        "pidx_on_plane2 = np.where(distances2 < disp_mm)[0]\n",
        "p2 = np.intersect1d(p, pidx_on_plane2)\n",
        "print(\"Points within %2.0f mm of the 2nd plane are shown in red.\" % (disp_mm))\n",
        "xyz = points[p2,:]\n",
        "\n",
        "trace_p2 = go.Scatter3d(x=xyz[:,0], y=xyz[:,1], z=xyz[:,2], mode='markers',\n",
        "                           marker=dict(size=2, color='rgb(255,0,0)',\n",
        "                           opacity=0.05))\n",
        "\n",
        "layout = go.Layout(margin=dict(l=0,r=0,b=0,t=0))\n",
        "fig = go.Figure(data=[trace, trace_p1, trace_p2], layout=layout)\n",
        "camera = dict(up=dict(x=0, y=0, z=1), center=dict(x=0, y=-0.4, z=0), eye=dict(x=0, y=0.8, z=-2))\n",
        "fig.update_layout(scene_camera=camera)\n",
        "\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}