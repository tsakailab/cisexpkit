{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPiHB9yrj90f"
      },
      "source": [
        "# 逆透視変換による3次元復元"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0RSELq3j90g"
      },
      "source": [
        "## RealSenseを接続してください．\n",
        "pyrealsenseを使います．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UFSkEVwutRBD"
      },
      "outputs": [],
      "source": [
        "import pyrealsense2 as rs\n",
        "import numpy as np\n",
        "import cv2\n",
        "from IPython.display import Image, display\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Configure color and depth to run at VGA resolution at 30 frames per second\n",
        "config = rs.config()\n",
        "config.enable_stream(rs.stream.depth)\n",
        "config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)\n",
        "config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSocSBVEj90i"
      },
      "source": [
        "## カラー画像と深度画像を取得して表示・保存します．\n",
        "スペースキーを押す毎に画像が連番で保存されます．'q'を押すと終了します．最後に保存したデータが点群の作成に使われます．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N2qNjk_GtRBS"
      },
      "outputs": [],
      "source": [
        "# Start streaming\n",
        "pipeline = rs.pipeline()\n",
        "profile = pipeline.start(config)\n",
        "\n",
        "# Get camera parameters\n",
        "intr = profile.get_stream(rs.stream.depth).as_video_stream_profile().get_intrinsics()\n",
        "scale = config.resolve(rs.pipeline_wrapper(pipeline)).get_device().first_depth_sensor().get_depth_scale()\n",
        "\n",
        "print(\"focal length(x) in pixels = \", intr.fx)\n",
        "print(\"focal length(y) in pixels = \", intr.fy)\n",
        "print(\"image height = \", intr.height)\n",
        "print(\"image width = \", intr.width)\n",
        "print(\"ppx = \", intr.ppx)\n",
        "print(\"ppy = \", intr.ppy)\n",
        "\n",
        "# Create a camera alignment object (depth aligned to color)\n",
        "align = rs.align(rs.stream.color)\n",
        "max_depth = 2.0 / scale # Zeros out for any depth greater than 2.0 meters\n",
        "\n",
        "# Display and save images\n",
        "print(\"Press [SPACE] to save images (png) and depth data (npy).\")\n",
        "print(\"Press 'q' to stop.\")\n",
        "nsaved = 0\n",
        "try:\n",
        "    while True:\n",
        "        # Wait for a coherent pair of frames: depth and color\n",
        "        frames = pipeline.wait_for_frames()\n",
        "        aligned_frames = align.process(frames)\n",
        "        color_frame = aligned_frames.get_color_frame()\n",
        "        depth_frame = aligned_frames.get_depth_frame()\n",
        "        if not depth_frame or not color_frame:\n",
        "            continue\n",
        "\n",
        "        # Convert images to numpy arrays\n",
        "        bgr = np.asanyarray(color_frame.get_data())\n",
        "        depth = np.asanyarray(depth_frame.get_data())\n",
        "        depth[depth > max_depth] = 0 # Zeros out\n",
        "\n",
        "        # Apply colormap on depth image (image must be converted to 8-bit per pixel first)\n",
        "        depth_colormap = cv2.applyColorMap(cv2.normalize(depth, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U),\n",
        "                                           cv2.COLORMAP_JET)\n",
        "\n",
        "        images = np.hstack((bgr, depth_colormap))\n",
        "        # Show images\n",
        "        cv2.namedWindow('RealSense', cv2.WINDOW_AUTOSIZE)\n",
        "        cv2.imshow('RealSense', images)\n",
        "\n",
        "        key = cv2.waitKey(33)\n",
        "        if key == ord(' '):\n",
        "            Z = depth * scale * 1e+3 # unit in mm\n",
        "            color = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            # Save images\n",
        "            cv2.imwrite('color{:02d}pc.png'.format(nsaved), bgr)\n",
        "            cv2.imwrite('depth{:02d}pc.png'.format(nsaved), depth_colormap)\n",
        "            np.save('Z{:02d}pc.npy'.format(nsaved), Z)\n",
        "\n",
        "            print(\"color image and depth data are saved ({:02d})\".format(nsaved))\n",
        "            nsaved += 1\n",
        "\n",
        "        elif key == ord('q'):\n",
        "            if nsaved == 0:\n",
        "                Z = depth * scale * 1e+3 # unit in mm\n",
        "                color = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)\n",
        "            cv2.destroyAllWindows()\n",
        "            break\n",
        "\n",
        "finally:\n",
        "    # Stop streaming\n",
        "    pipeline.stop()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGBNQn9Rj90m"
      },
      "source": [
        "## 逆透視変換でポイントクラウドを作りましょう．\n",
        "カラー画像および点群を作成する深度データを可視化します．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8FmUdTtztRBW"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "height, width, _ = color.shape\n",
        "plt.figure(figsize=(15,4))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(color)\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(Z, cmap=\"gray\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8021yxtnj90n"
      },
      "source": [
        "### 各画素にuとvの座標を設定します．座標系は[予習事項](https://github.com/tsakailab/cisexpkit/blob/master/Experiment/Document/preparation.pdf)の図1です．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aVFSGtoEtRBX"
      },
      "outputs": [],
      "source": [
        "# 主点を設定します．\n",
        "cx, cy = intr.ppx, intr.ppy # width*0.5, height*0.5\n",
        "j_to_u = lambda j: -(j - cx)\n",
        "i_to_v = lambda i: -(i - cy)\n",
        "# 画像平面の座標を設定します．\n",
        "u, v = np.meshgrid(j_to_u(np.arange(width)), i_to_v(np.arange(height)))\n",
        "print(u, u.shape)\n",
        "print(v, v.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmtdR-1Dj90o"
      },
      "source": [
        "### Z, u, vが与えられたとき，X[mm]とY[mm]を計算する関数を作りましょう．[ヒント：予習事項の問2](https://github.com/tsakailab/cisexpkit/blob/master/Experiment/Document/preparation.pdf)\n",
        "\n",
        "Q11: 関数 Zuv_to_XYを完成させよ．単位mmの深度Zと，画素数の単位をもつ座標u, v, 焦点距離fが与えられているものとする．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMnVo0cOtRBZ"
      },
      "outputs": [],
      "source": [
        "focal_length = [intr.fx, intr.fy] # in pixels\n",
        "def Zuv_to_XY(Z, u, v, f=focal_length):\n",
        "    ### X = ________   # Z, u, v, f[0], f[1] から必要なものを使って計算する\n",
        "    ### Y = ________   # Z, u, v, f[0], f[1] から必要なものを使って計算する\n",
        "    return X, Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0OWR-JBMtRBa",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Z, u, v から X, Y を計算します．\n",
        "X, Y = Zuv_to_XY(Z, u, v)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "if1mMRohj90p"
      },
      "source": [
        "## ポイントクラウドを可視化して観察しましょう．\n",
        "\n",
        "Q12: 使用した画像のサイズと全画素数，および深度画像の画素値がゼロでない画素の数はいくらか．\n",
        "\n",
        "Q13: 逆透視変換できない点が生じる原因を複数述べよ．\n",
        "\n",
        "Q14: [plotly](https://plotly.com/)とは何か．特に，[plotly Graphing Libraries](https://plotly.com/graphing-libraries/)はどのような特長があるか．\n",
        "> マウスで視点や拡大・縮小をコントロールできます．描画領域右上にある機能も活用しましょう．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_p_nPc9jtRBb",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "nd = np.count_nonzero(Z)\n",
        "n = 30000\n",
        "p = np.random.choice(nd, min(n,nd), replace=False)\n",
        "print(\"%d out of %d points are displayed.\" % (n, nd))\n",
        "\n",
        "import plotly.graph_objs  as go\n",
        "rgb = color[Z>0][p] # * 1.5 # brighter\n",
        "\n",
        "trace = go.Scatter3d(x=X[Z>0][p], y=Y[Z>0][p], z=Z[Z>0][p], mode='markers',\n",
        "                     marker=dict(size=2,\n",
        "                                color=['rgb({},{},{})'.format(r,g,b) for r,g,b in zip(rgb[:,0], rgb[:,1], rgb[:,2])],\n",
        "                                opacity=0.8))\n",
        "\n",
        "layout = go.Layout(margin=dict(l=0,r=0,b=0,t=0))\n",
        "fig = go.Figure(data=[trace], layout=layout)\n",
        "camera = dict(up=dict(x=0, y=0, z=1), center=dict(x=0, y=-0.4, z=0), eye=dict(x=0, y=0.8, z=-2))\n",
        "fig.update_layout(scene_camera=camera)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 誤差について考察しましょう．\n",
        "\n",
        "可視化したポイントクラウドの点にマウスを合わせると，その点の3次元座標(X,Y,Z)が表示されます．例えば，2点の座標を調べれば，2点間の距離を計算できます（長さの計測）．\n",
        "\n",
        "\n",
        "Q15: 点の位置や，長さ計測には，どのような原因で誤差が生じると考えられるか．<br>　　両眼ステレオ視において[系統誤差（systematic errors）](https://ja.wikipedia.org/wiki/%E8%AA%A4%E5%B7%AE#%E7%B3%BB%E7%B5%B1%E8%AA%A4%E5%B7%AE)および[偶然誤差（random errors）](https://ja.wikipedia.org/wiki/%E8%AA%A4%E5%B7%AE#%E5%81%B6%E7%84%B6%E8%AA%A4%E5%B7%AE)が<br>　　生じる原因をそれぞれ挙げよ．また，各原因によって誤差が生じる仕組みを説明せよ．\n",
        "\n",
        "> 系統誤差と偶然誤差は，原因や性質が異なります．計測における[正確度（accuracy）と精度（precision）](https://ja.wikipedia.org/wiki/%E6%AD%A3%E7%A2%BA%E5%BA%A6%E3%81%A8%E7%B2%BE%E5%BA%A6)について必ず理解し，両者を混同しないように注意してください．\n",
        "\n",
        "> 例えば，遠近の2点間を測る場合と，上下または左右の位置関係にある2点間を測る場合では，誤差の原因が異なります．ヒント：X,Y,Zはそれぞれ何から算出していますか？\n",
        "\n",
        "> 挙げた原因が正しいことを実験的に示すことは可能でしょうか．どのような設定で計測の結果を集めて整理すると，証拠が得られるでしょうか．実際に実験するのが望ましいですが，実験方法と予想される結果について考えを述べるだけでも有意義です．"
      ],
      "metadata": {
        "id": "OtfDueePknB7"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}